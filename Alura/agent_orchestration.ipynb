{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b956aff",
   "metadata": {},
   "source": [
    "Complete AI Agent orchestration with langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50319239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df65af96",
   "metadata": {},
   "source": [
    "Triage chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5114c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class TriageOut(BaseModel):\n",
    "    decision: Literal[\"SELF_RESOLVE\",\"ASK_FOR_INFO\",\"OPEN_TICKET\"]\n",
    "    urgency: Literal[\"LOW\", \"MEDIUM\", \"HIGH\"]\n",
    "    missing_fields: list[str] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42998fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    api_key=GOOGLE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f3d4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "triage_Prompt = (\"\"\"\n",
    "                    Você é um triador de Service Desk para políticas internas da empresa Carraro Desenvolvimento.\n",
    "Dada a mensagem do usuário, retorne SOMENTE um JSON com:\n",
    "{\n",
    "  \"decisao\": \"AUTO_RESOLVER\" | \"PEDIR_INFO\" | \"ABRIR_CHAMADO\",\n",
    "  \"urgencia\": \"BAIXA\" | \"MEDIA\" | \"ALTA\",\n",
    "  \"campos_faltantes\": [\"...\"]\n",
    "}\n",
    "\n",
    "Regras de Decisão:\n",
    "- **AUTO_RESOLVER**: Perguntas claras sobre regras ou procedimentos descritos nas políticas (Ex: \"Posso reembolsar a internet do meu home office?\", \"Como funciona a política de alimentação em viagens?\").\n",
    "- **PEDIR_INFO**: Mensagens vagas ou que faltam informações para identificar o tema ou contexto (Ex: \"Preciso de ajuda com uma política\", \"Tenho uma dúvida geral\"). \n",
    "  # Melhoria: Instrução para preencher campos_faltantes de forma útil.\n",
    "  Ao usar esta decisão, preencha \"campos_faltantes\" com os tópicos que precisam de esclarecimento (Ex: \"nome da política\", \"descrição do problema\").\n",
    "- **ABRIR_CHAMADO**: Pedidos de exceção, liberação, aprovação ou acesso especial, ou quando o usuário explicitamente pede para abrir um chamado (Ex: \"Quero exceção para trabalhar 5 dias remoto.\", \"Solicito liberação para anexos externos.\", \"Por favor, abra um chamado para o RH.\").\n",
    "\n",
    "Regras de Urgência:\n",
    "- **ALTA**: O usuário relata um problema que o impede completamente de trabalhar, menciona risco de segurança, legal ou perda de dados. (Ex: \"Não consigo acessar o sistema para trabalhar\", \"Recebi um e-mail de phishing e cliquei no link\").\n",
    "- **MEDIA**: O usuário tem um problema que dificulta o trabalho mas não o impede, ou tem um prazo se aproximando. (Ex: \"Preciso da aprovação para uma viagem na próxima semana\").\n",
    "- **BAIXA**: Perguntas gerais, dúvidas sobre políticas ou solicitações que não têm um prazo imediato. (Ex: \"Como funciona a política de férias?\", \"Tenho uma dúvida sobre reembolso\").\n",
    "\n",
    "Analise a mensagem e decida a ação e urgência mais apropriadas com base nas regras acima.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0488c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "triage_chain = llm.with_structured_output(TriageOut)\n",
    "\n",
    "def triage(message:str) ->dict:\n",
    "    output: TriageOut = triage_chain.invoke([\n",
    "        SystemMessage(content=triage_Prompt),\n",
    "        HumanMessage(content=message)\n",
    "    ])\n",
    "    return output.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1449c485",
   "metadata": {},
   "source": [
    "RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11a96793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file loaded succesifuly: Política de Reembolsos (Viagens e Despesas).pdf\n",
      "file loaded succesifuly: Política de Uso de E-mail e Segurança da Informação.pdf\n",
      "file loaded succesifuly: Políticas de Home Office.pdf\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "docs = []\n",
    "data_path = Path('text_docs/')\n",
    "for d in data_path.glob(\"*.pdf\"):\n",
    "    try:\n",
    "        loader = PyMuPDFLoader(str(d))\n",
    "        docs.extend(loader.load())\n",
    "        print(f\"file loaded succesifuly: {d.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"failed to load the file {d.name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "917c12c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
    "\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6077748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model = \"models/gemini-embedding-001\",\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c55500aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_type= 'similarity_score_threshold',\n",
    "                                     search_kwargs = {'score_threshold':0.3,'k':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert HR and IT assistant for the company 'Torres Devs'. \"\n",
    "               \"Your main task is to answer employee questions based ONLY on the context provided. \"\n",
    "               \"Be polite and professional in your responses. \"\n",
    "               \"If the information to answer the question is not in the provided context, \"\n",
    "               \"clearly state that you cannot find the answer in the company's documents.\"),\n",
    "    \n",
    "    (\"user\", \"Based on our company's policies, please answer the following question:\\n\\nQuestion: {input}\\n\\nContext:\\n{context}\")\n",
    "])\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, rag_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482cec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question_rag(question:str) -> dict:\n",
    "    related_docs = retriever.invoke(question)\n",
    "\n",
    "    if not related_docs:\n",
    "        return {\"answer\": \"cannot find the answer in the company's documents\",\n",
    "                \"citations\":[],\n",
    "                \"context_found\": False}\n",
    "    \n",
    "    answer = document_chain.invoke({\"input\": question,\n",
    "                                    \"context\": related_docs})\n",
    "    text = (answer or \"\").strip()\n",
    "\n",
    "    if text.rstrip(\".!?\") == \"cannot find the answer in the company's documents\":\n",
    "        return {\"answer\": \"cannot find the answer in the company's documents\",\n",
    "                \"citations\":[],\n",
    "                \"context_found\": False}\n",
    "    return {\"answer\": text,\n",
    "                \"citations\":related_docs,\n",
    "                \"context_found\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb775a1",
   "metadata": {},
   "source": [
    "CODIGO DA AULA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3d3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional, Dict, List\n",
    "\n",
    "class AgentState(TypedDict, total = False):\n",
    "    mensagem: str\n",
    "    triage: dict\n",
    "    answer: Optional[str]\n",
    "    citations: List[dict]\n",
    "    rag_succes: bool\n",
    "    final_action: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc62184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_node(state: AgentState) -> AgentState:\n",
    "    print(\"Executing the triaging node\")\n",
    "    return {\"triage\": triage(state[\"message\"])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_resolve_node(state: AgentState) -> AgentState:\n",
    "    print(\"Executing the self resolve node\")\n",
    "    rag_answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
